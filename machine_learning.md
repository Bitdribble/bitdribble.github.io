---
layout: page
mathjax: true
title: Machine Learning
---
#### Books, Lecture Notes
* Michael Nielsen: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
* [Pattern Recognition and Machine Learning](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738), C. Bishop, [pdf](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)
* [Artificial Intelligence: A Modern Approach](repository.unimal.ac.id/1022/1/Artificial%20Intelligence%20-%20A%20Modern%20Approach%203rd%20Ed%20-%20Stuart%20Russell%20and%20Peter%20Norvig%2C%20Berkeley%20%282010%29.pdf), by Russell and Norvig (4th edition, 2020)
* [Machine Learning: A Probabilistic Perspective](https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020), Kevin Murphy (2012)
* [Deep learning theory lecture notes](https://mjt.cs.illinois.edu/dlt/), Matus Telgarsky
* [Fundamentals of Machine Learning for Predictive Data Analytics](https://www.amazon.com/Fundamentals-Machine-Learning-Predictive-Analytics/dp/0262044692/ref=asc_df_0262044692/), J.D. Kelleher et al (2020)
* [Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond](https://www.amazon.com/Learning-Kernels-Regularization-Optimization-Computation/dp/0262194759), B. Scholkopf, A. Smola (2001)
* [Bio-Inspired Artificial Intelligence: Theories, Methods, and Technologies](https://www.amazon.com/Bio-Inspired-Artificial-Intelligence-Technologies-Intelligent/dp/0262062712), D. Floreano, C. Mattiussi (2008)
* [Deep Learning](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/), I. Goodfellow, Y. Bengio, A. Courville (2016)
* [Deep Learning Systems: Algorithms, Compilers, and Processors for Large-Scale Production](https://deeplearningsystems.ai/), Andres Rodriguez (2020)
* [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/14920326461): Concepts, Tools, and Techniques to Build Intelligent Systems, by Aurelien Geron (2nd ed, 2019) ([Jupyter notebooks](https://github.com/ageron/handson-ml2)). Very complete, but using TensorFlow. 
* [Python Machine Learning Cookbook](https://www.amazon.com/Machine-Learning-Python-Cookbook-Preprocessing/dp/1491989386/ref=asc_df_1491989386/), Chris Albon (2018)
* [Learning Machine Learning](https://www.informit.com/store/learning-deep-learning-theory-and-practice-of-neural-9780137470358), M. Ekman (2021), [github](https://github.com/NVDLI/LDL/tree/main/pt_framework)
* [fast.ai](https://www.fast.ai/), [Deep Learning for Coders with Fastai and PyTorch](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527), J. Howard and S. Gugger (2020)
* [Advanced Applied Deep Learning](https://www.amazon.com/Advanced-Applied-Deep-Learning-Convolutional/dp/1484249755), CNNs and Object Detection, by U. Michelucci
* [Python Deep Learning](https://www.amazon.com/Python-Deep-Learning-techniques-architectures-ebook/dp/B07KQ29CQ3), Exploring deep learning techniques and neural network architectures with PyTorch, Keras, and TensorFlow, I. Vasiliev el al (2019), [github](https://github.com/ivan-vasilev/Python-Deep-Learning-SE)

#### Courses
* P. Abbeel: [Foundations of Deep RL in 6 Lectures](https://www.youtube.com/watch?v=2GwBez0D20A&list=PLwRJQ4m4UJjNymuBM9RdmB3Z9N5-0IlY0) (2021), [slides](https://www.dropbox.com/s/f9xyrdkpqugtrvq/l1-mdps-exact-methods.pdf?dl=0)
* Yann LeCun [Deep Learning](https://www.youtube.com/watch?v=ChLEJA6J2b8&list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7&index=6) course at College de France (2016)
* G. Hinton: [Neural Networks for Machine Learning](https://www.cs.toronto.edu/~hinton/coursera_lectures.html) (2012)
* Berkeley
  * [CS287-FA19](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/): Advanced Robotics (2020), [youtube](https://www.youtube.com/watch?v=xWPViQ6LI-Q&list=PLwRJQ4m4UJjNBPJdt8WamRAt4XKc639wF), P. Abbeel
  * [CS294-158-SP20](https://sites.google.com/view/berkeley-cs294-158-sp20/home): Deep Unsuperviser Learning (Spring 2020), [youtube](https://www.youtube.com/watch?v=V9Roouqfu-M&list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP&index=1) ([Spring 2019](https://sites.google.com/view/berkeley-cs294-158-sp19/home))
* DeepMind: [David Silver: Introduction to Reinforcement Learning](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)
* FastAI: [Practical Deep Learning for Coders](https://course.fast.ai/), Jeremy Howard et al.
* Hugo Larochelle: math heavy [Neural networks class](https://www.youtube.com/watch?v=SGZ6BttHMPw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH), Universit√© de Sherbrooke]
* MIT
  * 6.036 Artificial Intelligence: Patrick Winston Fall 2010 [videos](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi), Tamara Broderick Fall 2020 [videos](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi), [slides](https://tamarabroderick.com/ml.html)
  * 6.S191 Introduction to Deep Learning, [IAP 2022](http://introtodeeplearning.com/) [upcoming videos](https://www.youtube.com/channel/UCtslD4DGH6PKyG_1gFAX7sg)
  * 9.520/6.860 Statistical Learning Theory and Applications, [Fall 2019](http://www.mit.edu/~9.520/fall19/), [Fall 2021](https://cbmm.mit.edu/9-520), [videos](https://cbmm.mit.edu/9-520/videos)
* [Stanford](https://www.youtube.com/user/stanfordonline/playlists)
  * [CS221](https://stanford-cs221.github.io): Artificial Intelligence: Principles and Techniques (Autumn 2019), [syllabus](https://stanford-cs221.github.io/autumn2019/),[video](https://www.youtube.com/watch?v=J8Eh7RqggsU&list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX)
  * CS229 - Machine Learning, Autumn 2018 [video](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) , [slides](http://cs229.stanford.edu/syllabus-autumn2018.html), Summer 2021 [video, slides](http://cs229.stanford.edu/syllabus-summer2019.html)
  * [CS231n](http://cs231n.stanford.edu/): Convolutional Neural Networks for Visual Recognition (Spring 2017), [syllabus](https://cs231n.github.io/), [2016 video](https://www.youtube.com/watch?v=NfnWJUyUJYU&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC), [2017 videos](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv), [2017 slides](http://cs231n.stanford.edu/slides/2017), [2021 slides](http://cs231n.stanford.edu/slides/2021)
    * Karpathy's [ConvNetJS CIFAR-10 demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)
  * [CS236](https://deepgenerativemodels.github.io/): Deep Generative Models (slides only)
  * [CS224n](http://web.stanford.edu/class/cs224n/):Natural Language Processing with Deep Learning [Winter 2017 video](https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6), [Winter 2019 video](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)
  * [CS224W](http://web.stanford.edu/class/cs224w): Machine Learning with Graphs [Spring 2021 video](https://www.youtube.com/watch?v=JAB_plj2rbA&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)

#### Seminars
* [Stanford MLSys Seminars](https://www.youtube.com/channel/UCzz6ructab1U44QPI3HpZEQ/videos)

#### Conferences
* [CVPR '20](https://cvpr2020.thecvf.com/)
* [ICLR](https://iclr.cc/)
* [ICML](https://icml.cc/)
* [NAACL '21](https://2021.naacl.org/)
* [NeurIPS](https://nips.cc/)
* [OpML '20](https://www.usenix.org/conference/opml20/conference-program)

#### Languages
* PyTorch
  * [Deep Learning with PyTorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf), Stevens, Antiga, Viehmann (2020), [github]((https://github.com/deep-learning-with-pytorch/dlwpt-code)
  * [CS224N](https://web.stanford.edu/class/cs224n/): [PyTorch Tutorial](https://web.stanford.edu/class/cs224n/materials/CS224N_PyTorch_Tutorial.html), [ipynb](https://web.stanford.edu/class/cs224n/materials/CS224N PyTorch Tutorial.ipynb), Dilara Soylu (Winter '21), Jupyter notebooks [fork](https://github.com/Bitdribble/cs224n)
* TensorFlow
  * [CS231_n](http://cs231n.stanford.edu) [Lecture 8, Deep Learning Software](https://www.youtube.com/watch?v=6SlgtELqOWc&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=8&t=3s), [2017 slides](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf), [2021 slides](http://cs231n.stanford.edu/slides/2021/lecture_6.pdf) compares TensorFlow, PyTorch, Caffe, discusses static and dynamic computation graphs
  * [Keras Tutorials](https://techvidvan.com/tutorials/keras-introduction-tutorial/)
* Others: Caffe(Berkeley), Caffe2(Facebook), MXNet(Amazon), CNTK(Microsoft), Paddle(Baidu)

#### Tutorials
* Robbie Allen: [Over 200 of the Best Machine Learning, NLP, and Python Tutorials](https://medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc) (2018)

#### Convolutional Nets
* [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/pdf/1512.00567v1.pdf), C. Szegedy el at (2015)
* Blog: [Speeding up Convolutional Neural Networks](https://towardsdatascience.com/speeding-up-convolutional-neural-networks-240beac5e30f), [Alex Burlacu](https://alexandruburlacu.github.io/) (2018)

#### Videos
* 3Blue1Brown Series
  * [What is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk)
  * [Gradient descent, how neural networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w)
  * [What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U)
  * [Backpropagation calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8)
* sentdex: Deep Learning and Neural Networks with Python and Pytorch
  * [Intro](https://www.youtube.com/watch?v=BzcBsTou0C0)
  * [Data](https://www.youtube.com/watch?v=i2yPxY2rOzs)
  * [Building our neural Network](https://www.youtube.com/watch?v=ixathu7U-LQ)
  * [Training model](https://www.youtube.com/watch?v=9j-_dOze4IM)
  * ...
* Welch Labs
  * [Learning To See](https://www.youtube.com/watch?v=i8D90DkCLhI)
  * [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs)
* MIT 6.5191 [Introduction to Deep Learning](https://www.youtube.com/watch?v=njKP3FqW3Sk&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI) (2020)
  * [Convolutional Neural Networks](https://www.youtube.com/watch?v=iaSUYvmCekI), Alexander Amini
  * [Deep Generative Modeling](https://www.youtube.com/watch?v=rZufA635dq4&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=4), Ava Soleimany
  * [Deep Reinforcement Learning](https://www.youtube.com/watch?v=i6Mi2_QM3rA), Alexander Amini
* J. Frankle, M. Carbin:[The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635) (2019)
* G. Hinton: [What is wrong with convolutional neural nets ?](https://www.youtube.com/watch?v=rTawFwUvnLE) (2017)
* G. Hinton: [Artificial Intelligence: Turning our understanding of the mind right side up](https://www.youtube.com/watch?v=fDR1I2Shw_E) (2017)

#### Interviews
* Lex Fridman
  * [Stephen Wolfram: Cellular Automata, Computation, and Physics](https://www.youtube.com/watch?v=ez773teNFYA&t=2539s), Lex Fridman Podcast #89 (2020)
  * [David Silver: AlphaGo, AlphaZero, and Deep Reinforcement Learning](https://www.youtube.com/watch?v=uPUEq8d73JI&t=2499s), Lex Fridman Podcast #86 (2020)
  * [Ian Goodfellow: Generative Adversarial Networks (GANs)](https://www.youtube.com/watch?v=Z6rxFNMGdn0&t=979s), Lex Fridman Podcast #19 (2019)
  * [Yann LeCun: Deep Learning, ConvNets, and Self-Supervised Learning](https://www.youtube.com/watch?v=SGSOCuByo24), Lex Firdman Podcast #36
  * [Andrew Ng: Deep Learning, Education, and Real-World AI](https://www.youtube.com/watch?v=0jspaMLxBig), Lex Fridman Podcast #73

#### Posts
* [Colah's blog](http://colah.github.io/)
* [distill.pub](https://distill.pub/)
* [MuZero](https://en.wikipedia.org/wiki/MuZero) and [The Evolution of AlphaGo to MuZero](https://towardsdatascience.com/the-evolution-of-alphago-to-muzero-c2c37306bf9)
* [McGill COMP-424 Intro to AI Lecture Notes](https://www.cs.mcgill.ca/~dprecup/courses/AI/Lectures) (Doina Precup, 2013), [Lecture 16, Why does a finite MDP optimal policy exist?](https://www.cs.mcgill.ca/~dprecup/courses/AI/Lectures/ai-lecture16.pdf)
* Open AI: [Safety Gym] (https://openai.com/blog/safety-gym/) (2019)
* [OpenAI Baselines](https://github.com/openai/baselines/), a set of high-quality implementations of reinforcement learning algorithms
* [ConvnetJS](https://cs.stanford.edu/people/karpathy/convnetjs/) demo: [Toy 2d classification with 2-layer neural network](https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html), A. Karpathy
* Adrian Rosebrock [tutorials](https://www.pyimagesearch.com/author/adrian/)
* The [Important Definitions](https://github.com/rafaelpadilla/Object-Detection-Metrics) of Rafael Padilla repo is a very good introduction to the relationship between IOU, precision/recall, PR curve, average precision
* [Ben Dickson](https://bdtechtalks.com/author/bendee983/): [The challenges of applied machine learning](https://bdtechtalks.com/2021/04/19/applied-machine-learning-challenges/) (2021)
* Jonathan Hui: [How to start a Deep Learning project?](https://jonathan-hui.medium.com/how-to-start-a-deep-learning-project-d9e1db90fa72) (2018)
* Georgii Evtushenko: [Multi-GPU Programming](https://medium.com/gpgpu/multi-gpu-programming-6768eeb42e2c)

#### Distributed Training
* Medium: [Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU & Distributed setups](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255), Thomas Wolf (2018)
* Towards Data Science: [Distributed Neural Network Training In Pytorch](https://towardsdatascience.com/distributed-neural-network-training-in-pytorch-5e766e2a9e62), Nilesh Vijayrania (2020)
* Serge-Paul Carrasco: [Distributed and Declarative Deep Learning Systems](https://asiliconvalleyinsider.com/2021/09/12/distributed-and-declarative-deep-learning-systems/) (2021)
* [Ludwig: A type-based declarative deep learning toolbox](https://arxiv.org/pdf/1909.07930.pdf)
* Horovod
  * [Docs](https://horovod.readthedocs.io/en/stable/)
  * [Horovod: Multi-GPU and multi-node data parallelism](http://www.idris.fr/eng/jean-zay/gpu/jean-zay-gpu-hvd-tf-multi-eng.html)
  * [Deep Learning at Scale with Horovod feat. Travis Addair](https://www.youtube.com/watch?v=DB7oOZ5hyrE&t=222s), Stanford MLSys Seminar Episode 10 (2021)
* [determined.ai](http://determined.ai)
  * [Why Slurm Makes Deep Learning Engineers Squirm](https://www.determined.ai/blog/slurm-lacking-deep-learning)
  * [Distributed Training using Apache MXNet with Horovod](https://medium.com/apache-mxnet/distributed-training-using-apache-mxnet-with-horovod-44f98bf0e7b7)
  * [AWS Machine Learning Blog](https://aws.amazon.com/blogs/machine-learning/horovod-mxnet-distributed-training/): [How to run distributed training using Horovod and MXNet on AWS DL Containers and AWS  Deep Learning AMIs](https://aws.amazon.com/blogs/machine-learning/horovod-mxnet-distributed-training/)
* [DRAGON: A Dynamic Scheduling and Scaling Controller for Managing Distributed Deep Learning Jobs in Kubernetes Cluster](https://www.scitepress.org/Papers/2019/77076/77076.pdf), C. Lin et al (2019)
* [Analysis and Comparison of Distributed Training Techniques for Deep Neural Networks in a Dynamic Environment](http://kth.diva-portal.org/smash/get/diva2:1224181/FULLTEXT01.pdf), E. Gebremeskel (2018)
* [Bringing HPC Techniques to Deep Learning](https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/), Andrew Gibiansky (2017)
* [Fast Multi-GPU collectives with NCCL](https://developer.nvidia.com/blog/fast-multi-gpu-collectives-nccl/), Nathan Luehr, NVidia (2016)

#### Optimization
* [CS231n](http://cs231n.stanford.edu/) [Lecture 7](https://www.youtube.com/watch?v=_JB0AO7QxSA&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=7&t=13s) (2017)
* [Practical Recommendations for Gradient-Based Training of Deep
Architectures](https://arxiv.org/pdf/1206.5533v2.pdf), Y. Bengio (2012)
* [On the importance of initialization and momentum in deep learning](https://www.cs.toronto.edu/~fritz/absps/momentum.pdf), I. Sutskever et al (2013)
* [Identifying and attacking the saddle point problem in high-dimensional non-convex optimization](https://arxiv.org/pdf/1406.2572.pdf), Y. Dauphin et al (2014)
* [optim.Adam vs optim.SGD. Let‚Äôs dive in](https://medium.com/@Biboswan98/optim-adam-vs-optim-sgd-lets-dive-in-8dbf1890fbdc)
* [fast.ai](https://www.fast.ai): [AdamW and Super-convergence is now the fastest way to train neural nets ](https://www.fast.ai/2018/07/02/adam-weight-decay/), by S. Gugger and J. Howard (2018)

#### Articles
* [How neural networks learn from experience](http://www.cs.toronto.edu/~hinton/absps/sciam92.pdf), G. Hinton (1992)
* [Neural networks and physical systems with emergent collective computational abilities](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238/pdf/pnas00447-0135.pdf), J. J. Hopfield (1982)
* [Reducing the Dimensionality of Data with Neural Networks](https://www.cs.toronto.edu/~hinton/science.pdf), G. E. Hinton and R. R. Salakhutdinov (2006), using Bolzmann machines to initialize weights close to a good solution
* [A Tutorial on Energy-Based Learning](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf), Y. LeCun et al (2006)
* [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf), Alex Krizhevsky, Ilya Sutskever and Geoffrey E. Hinton (2012), describes the AlexNet Conv network.
* [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/pdf/1703.03400.pdf), C. Finn, P. Abbeel, S. Levine (2017)
  * S. Khodadadeh: [Model Agnostic Meta Learning](https://www.youtube.com/watch?v=wT45v8sIMDM) (2018)
  * Deep Learning Explainer: [Toward Efficient Learning: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://www.youtube.com/watch?v=tGTNplKgt6Q) (2020)
* [Meta-Learning with Implicit Gradients](https://arxiv.org/pdf/1909.04630.pdf), A. Rajeswaran et al (2019), [video](https://www.youtube.com/watch?v=u5BkO8XMS2I)
* [The Mechanics of n-Player Differentiable Games](https://arxiv.org/pdf/1802.05642.pdf), D. Balduzzi et al (2018)
* [Simple, Distributed, and AcceleratedProbabilistic Programming](https://arxiv.org/pdf/1811.02091.pdf), D. Tran et al (2018)
* [Machine Theory of Mind](https://arxiv.org/pdf/1802.07740.pdf), N.C. Rabinowitz et al (2018)
* [Recent Advances in Deep Learning for Object Detection](https://arxiv.org/pdf/1908.03673.pdf), X. Wu (2019)
* [Online Bayesian Goal Inference for Boundedly-Rational Planning Agents](https://arxiv.org/pdf/2006.07532.pdf), T. Zhi-Xuan et al (2020)
* [Open Problems in Cooperative AI](https://arxiv.org/pdf/2012.08630.pdf), A. Dafoe et al (2020)
* [Rethinking the maturity of artificial intelligence in safety-critical settings](http://hal.pratt.duke.edu/sites/hal.pratt.duke.edu/files/u36/reality%20check%20final_compressed.pdf), M.L. Cummings, 2019
* Sendtex tutorials at https://pythonprogramming.net
* [Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis](https://arxiv.org/pdf/1802.09941.pdf), Bel-Nun, Hoefler (2018), [video](https://www.youtube.com/watch?v=xtxxLWZznBI)
* Medium: [RegNet or How to methodologically design effective networks](https://medium.com/analytics-vidhya/regnet-or-how-to-methodologically-design-effective-networks-c3560c1cf436), Chris Ha (2000)
* [Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users](https://arxiv.org/pdf/2007.06823.pdf), L. V. Jospin et al (2021)

#### Network tuning
* [How to Avoid Overfitting in Deep Learning Neural Networks](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/), J. Brownlee (2018)

#### Image style transfer
* [Texture Synthesis Using Convolutional Neural Networks](https://proceedings.neurips.cc/paper/2015/file/a5e00132373a7031000fd987a3c9f87b-Paper.pdf), L.A.Gatys et al (2016) [code](https://github.com/leongatys/DeepTextures)
* [Image Style Transfer Using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf), L.A.Gatys et al (2016), [torch models by J.C.Johnson](https://github.com/jcjohnson/neural-style)
* [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/pdf/1603.08155.pdf), J. Johnson et al (2016)

#### Object Detection from Point Clouds
* PapersWithCode: [PointPillars](https://paperswithcode.com/search?q_meta=&q_type=&q=pointpillars)
  * [PointPillars: Fast Encoders for Object Detection from Point Clouds](https://arxiv.org/pdf/1812.05784v2.pdf), Alex H. Lang et al (2019)
  * [Optimisation of the PointPillars network for 3D object detection in point clouds](https://arxiv.org/pdf/2007.00493v1.pdf), J. Stanisz et al (2020)

#### Object Detection from Images
* [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640v5.pdf), J. Redmon et al (2016), [http://pjreddie.com/yolo/](http://pjreddie.com/yolo/), Y Liao et al (2021)

#### Geometric Deep Learning
* Michael Bronstein: [Geometric Deep Learning: the Erlangen Programme of ML](https://iclr.cc/virtual/2021/invited-talk/3717) (2021)
  * [Geometric Deep Learning: Grids, Groups, Graphs,Geodesics, and Gauges](https://arxiv.org/pdf/2104.13478.pdf), M. Bronstein et al (2021)
  * ML Street Talk #60: [Geometric Deep Learning Blueprint](https://www.youtube.com/watch?v=bIZB1hIJ4u8) (2021)
* Max Welling
  * ML Street Talk #36: [Max Welling: Quantum, Manifolds & Symmetries in ML](https://www.youtube.com/watch?v=mmDw5glry9w) (2021)
  * IAS Seminar on Theoretical ML: [Graph Nets: The Next Generation](https://www.youtube.com/watch?v=Wx8J-Kw3fTA) (2020)

#### Web sites
* [Papers with Code](https://paperswithcode.com/)

#### MLOps
* D. Sculley et al: [Hidden Technical Debt in Machine Learning Systems](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf) (2015)

#### People
* [Justin Johnson](https://web.eecs.umich.edu/~justincj/)

#### Other
* [Artificial Intelligence](artificial_intelligence.md)
* [Cloud Data Platform](cloud_data_platform.md)
* [Cognitive Science](cognitive_science.md)
* [Computation Theory](computation_theory.md)
* [Meta Learning](meta_learning.md)
* [MLOps](mlops.md)
* [Natural Language Processing](natural_language_processing.md)
* [Probabilities and Statistics](probabilities_and_statistics.md)
* [Robotics](robotics.md)
* [Self Driving Cars](self_driving_cars.md)
* [Computational Topology](computational_topology.md)
