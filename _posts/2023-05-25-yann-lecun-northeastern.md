---
title: "Yann LeCun's Northeastern University Talk"
layout: post
categories: machine_learning
---

Summary of Yann LeCun's talk at Northeastern:
- He is critical of Large Language Models (LLMs), saying that without further improvements, the vast parameters and computational power will ultimately lead to failure.
- He says LLMs are prone to numerous irreparable and uncontrollable hallucination errors, lacking reasoning and planning abilities.
- While LLMs they may approximate certain aspects of the human brain's Broca/Wernicke language areas, they fall far short of true human intelligence.

In terms of future AI development, LeCun puts forth several propositions.
- He predicts that LLM-based ChatGPT will fade into obscurity within five years.
- He emphasizes the necessity for future tech giants to prioritize the creation of open-source infrastructure for the next generation of artificial intelligence. This approach would eliminate the need for every company to compete solely based on computational power and parameter quantity.
- LeCun highlights the limitations of current AI systems, emphasizing their struggles with autonomous driving and the complexity of pharmaceutical engineering.
- As a result, AI applications remain confined to specific domains.

LeCun pointed out the significant risks associated with utilizing AI to read and write biomedical literature. LLMs can deceive laypeople by appearing knowledgeable, and even experts can detect fundamental misconceptions yet still be misled.

For professionals dedicated to fostering the healthy development of Artificial General Intelligence (AGI), LeCun offers some advice.
- He encourages them to deepen their understanding of the biological and neuroscientific foundations of animal and human learning, reasoning, and planning.
- He suggests gaining knowledge in statistical physics and quantum physics, thus establishing a robust foundation in science and technology beyond mere programming skills, which he considers to be low-level repetitive tasks that could potentially be replaced.
- He stresses the importance of cultivating critical and independent thinking to avoid succumbing to herd mentality.
- LeCun laments the numerous short-lived trends he has witnessed in the AI field, leaving behind nothing but confusion.

Andrei's take:
--------------

LeCun is Chief Scientist of Meta, and, from that position, things look different than, say, from OpenAI, or Google.

Meta is similar to OpenAI and Google in that it has a strong research-based data science group. But it is different in that it is focused on social media.

Meta does not provide cloud services like AWS and GCP, though it has a very sophisticated cloud as a back end for its multi-billion-strong user base.

Nor does Meta provide search or chatbot-based services to end users.

Meta basically sits on LLM and camera-based computer vision technology its engineers are perfectly capable to develop - but it's too preoccupied with social media competition from the likes of Tik-Tok to monetize on its internal LLM and computer vision research.

That explains LeCun's position, a bit. It's not like he's against LLMs and chat agents - or that he's dismissive of it.

What he's saying, rather, is that Meta will keep open sourcing its LLM tech stack, undercutting OpenAI and Google.

So, long term, LeCun says, we should expect LLMs and computer vision foundational algos to be commoditized, as a result of Meta's corporate strategy.
If Meta had the bandwidth to build a business around all this research it is doing, things would play out differently.

For more context on LeCun - his preprint [A Path Towards Autonomous Machine Intelligence](http://a%20path%20towards%20autonomous%20machine%20intelligence/) has a lot of stuff applicable to language models and langchain type applications.

And he's teaching an [NYU class on energy models and joint embeddings](https://cds.nyu.edu/deep-learning/).

The flavor of his work seems directed from challenges at Meta - where they sit on large amounts of text and vision data, and are looking to build self-supervised value out of that.

LeCun is also very theoretically minded. I think he might have a background in abstract math, or physics. He is a brilliant mind.
